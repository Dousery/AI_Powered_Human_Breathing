import streamlit as st
import pandas as pd
import numpy as np
import joblib
import pickle
import os
from datetime import datetime

# Streamlit sayfa konfigÃ¼rasyonu - en baÅŸta olmalÄ±
st.set_page_config(page_title="Hasta Durumu Tahminleme", layout="centered")

# Yeni eklenen kÃ¼tÃ¼phaneler ve fonksiyonlar
from scipy.signal import find_peaks
from scipy.stats import skew, kurtosis, entropy
from itertools import groupby
from scipy.fft import fft
from python_speech_features import mfcc # Bu kÃ¼tÃ¼phaneyi kurmanÄ±z gerekecek: pip install python_speech_features

# --- Model ve BileÅŸenleri YÃ¼kleme ---
model_dir = os.path.join(os.path.dirname(__file__), 'model') # app.py'nin olduÄŸu dizindeki 'model' klasÃ¶rÃ¼

try:
    ensemble_model = joblib.load(os.path.join(model_dir, 'best_model.joblib'))
    feature_selector = joblib.load(os.path.join(model_dir, 'feature_selector.joblib'))
    scaler = joblib.load(os.path.join(model_dir, 'scaler.joblib'))
    with open(os.path.join(model_dir, 'selected_features.pkl'), 'rb') as f:
        selected_features = pickle.load(f)
    st.sidebar.success("Model ve bileÅŸenler baÅŸarÄ±yla yÃ¼klendi!")
except FileNotFoundError:
    st.sidebar.error(f"Model dosyalarÄ± bulunamadÄ±. LÃ¼tfen '{model_dir}' klasÃ¶rÃ¼nÃ¼n doÄŸru konumda olduÄŸundan emin olun.")
    st.stop() # UygulamayÄ± durdur
except Exception as e:
    st.sidebar.error(f"Model yÃ¼klenirken bir hata oluÅŸtu: {e}")
    st.stop()

# --- Yeni Ã–zellik Ã‡Ä±karma Fonksiyonu (SeÃ§ili Ã–zellikler Ä°Ã§in) ---
def calculate_selected_features_only(breath_data, audio_data, max_val=4095):
    """Sadece seÃ§ili Ã¶zellikleri hesaplar"""
    
    # Verileri numpy array'e Ã§evir
    sensor_data = np.array(breath_data)
    audio_signal = np.array(audio_data)
    
    # Zirve noktalarÄ±nÄ± bul
    peaks, _ = find_peaks(sensor_data, height=max_val * 0.8, distance=10)
    peak_values = sensor_data[peaks] if len(peaks) > 0 else [0]
    
    # FFT hesapla (audio iÃ§in)
    fft_coeffs = np.abs(fft(audio_signal))[:len(audio_signal)//2]
    
    # TÃ¼m Ã¶zellikleri hesapla
    all_features = {
        'max_force': float(np.max(sensor_data)),
        'avg_peak_height': float(np.mean(peak_values)),
        'pef': float(np.max(sensor_data)),
        'breath_duration': float(len(sensor_data)),
        'fft_coeff_1': float(fft_coeffs[0] if len(fft_coeffs) > 0 else 0),
        'fft_coeff_4': float(fft_coeffs[3] if len(fft_coeffs) > 3 else 0),
        'mean_audio': float(np.mean(audio_signal)),
        'std_audio': float(np.std(audio_signal)),
        'min_audio': float(np.min(audio_signal)),
        'signal_energy': float(np.sum(audio_signal**2)),
        'rms_energy': float(np.sqrt(np.mean(audio_signal**2))),
        'fft_bandwidth': float(np.std(fft_coeffs)),
    }
    
    # MFCC Ã¶zellikleri
    try:
        mfcc_features = mfcc(audio_signal.astype(np.float32), samplerate=16000, numcep=13)
        mfcc_mean = np.mean(mfcc_features, axis=0)
        all_features['mfcc_1'] = float(mfcc_mean[0])
        all_features['mfcc_2'] = float(mfcc_mean[1])
        all_features['mfcc_5'] = float(mfcc_mean[4])
        all_features['mfcc_9'] = float(mfcc_mean[8])
        all_features['mfcc_12'] = float(mfcc_mean[11])
    except:
        all_features['mfcc_1'] = 0.0
        all_features['mfcc_2'] = 0.0
        all_features['mfcc_5'] = 0.0
        all_features['mfcc_9'] = 0.0
        all_features['mfcc_12'] = 0.0
    
    return all_features

def get_scaled_features(breath_data, audio_data):
    """SeÃ§ili Ã¶zellikleri hesaplar ve scaler ile normalize eder"""
    # TÃ¼m Ã¶zellikleri hesapla
    all_features = calculate_selected_features_only(breath_data, audio_data)
    
    # SeÃ§ili Ã¶zellikleri doÄŸru sÄ±rada dÃ¶ndÃ¼r
    feature_values = [all_features[feature] for feature in selected_features]
    
    # 2D array'e Ã§evir (scaler iÃ§in gerekli)
    features_2d = np.array(feature_values).reshape(1, -1)
    
    # Scaler'Ä± yÃ¼kle ve scale et
    scaled_features = scaler.transform(features_2d)
    
    return scaled_features[0], feature_values, all_features  # Scale edilmiÅŸ, ham ve tÃ¼m Ã¶zellikleri dÃ¶ndÃ¼r

# --- Eski Ã–zellik Ã‡Ä±karma Fonksiyonu (Geriye Uyumluluk Ä°Ã§in) ---
def extract_all_features(patient_age, patient_smoking, sensor_data, audio_signal, timestamps=None, max_val=4095):
    """KOAH hastalÄ±ÄŸÄ± tespiti iÃ§in nefes verisinden Ã¶zellikler Ã§Ä±karÄ±r"""

    # SensÃ¶r verisini NumPy array'e Ã§evir
    sensor_data = np.array(sensor_data)
    audio_signal = np.array(audio_signal)

    # EÄŸer zaman verisi saÄŸlanmadÄ±ysa, indeks numarasÄ±nÄ± zaman olarak kabul et
    if timestamps is None:
        timestamps = np.arange(len(sensor_data))
    else:
        timestamps = np.array(timestamps)

    # Zirve (peak) ve Ã§ukur (trough) noktalarÄ±nÄ± bul (EÄÄ°TÄ°MDEKÄ° GÄ°BÄ°)
    peaks, _ = find_peaks(sensor_data, height=max_val * 0.8, distance=10)
    troughs, _ = find_peaks(max_val - sensor_data, height=max_val * 0.8, distance=10)

    peak_values = sensor_data[peaks] if len(peaks) > 0 else [0]
    trough_values = sensor_data[troughs] if len(troughs) > 0 else [0]

    # FEV1/FVC oranÄ± (EÄÄ°TÄ°MDEKÄ° GÄ°BÄ°)
    fev1 = np.percentile(sensor_data, 75)  # YaklaÅŸÄ±k ilk %75'lik deÄŸer
    fvc = np.sum(sensor_data)  # Toplam nefes kapasitesi (yaklaÅŸÄ±k hesaplama)
    fev1_fvc_ratio = fev1 / fvc if fvc != 0 else 0

    # PEF (Peak Expiratory Flow) - Zirve nefes verme hÄ±zÄ±
    pef = np.max(sensor_data)

    # Solunum sÃ¼resi
    breath_duration = timestamps[-1] - timestamps[0] if len(timestamps) > 1 else 0

    # EÄŸilim (Trend) hesaplama
    slope = np.polyfit(timestamps, sensor_data, 1)[0] if len(sensor_data) > 1 else 0

    # Frekans alanÄ± analizi (Fourier Transform)
    fft_coeffs = np.abs(fft(sensor_data))[:10]  # Ä°lk 10 bileÅŸeni al

    # FFT hesapla (audio iÃ§in)
    fft_coeffs = np.abs(fft(audio_signal))[:len(audio_signal)//2]
    fft_probs = fft_coeffs / np.sum(fft_coeffs) if np.sum(fft_coeffs) > 0 else np.ones_like(fft_coeffs)

    features = {
         'patient_age': patient_age,
        'patient_smoking': patient_smoking,

        # Key statistical features for Breath
        'mean_force': np.mean(sensor_data),
        'std_force': np.std(sensor_data),
        'min_force': np.min(sensor_data),
        'max_force': np.max(sensor_data),
        'skewness': skew(sensor_data),
        'kurtosis': kurtosis(sensor_data),

        # Breath wave characteristics
        'num_peaks': len(peaks),
        'num_troughs': len(troughs),
        'avg_peak_height': np.mean(peak_values),
        'avg_trough_depth': np.mean(trough_values),
        'breath_amplitude': np.mean(peak_values) - np.mean(trough_values) if len(peaks) > 0 and len(troughs) > 0 else 0,
        'peak_variability': np.std(peak_values) if len(peaks) > 1 else 0,
        'trough_variability': np.std(trough_values) if len(troughs) > 1 else 0,
        'max_cluster': max(len(list(g)) for k, g in groupby(sensor_data == max_val)) if max_val in sensor_data else 0,

        # Critical features for COPD
        'fev1_fvc_ratio': fev1_fvc_ratio,  # KOAH teÅŸhisi iÃ§in kritik oran
        'pef': pef,  # Zirve nefes verme hÄ±zÄ±
        'breath_duration': breath_duration,  # Nefes sÃ¼resi
        'slope': slope,  # Nefes gÃ¼cÃ¼nÃ¼n zaman iÃ§indeki deÄŸiÅŸim eÄŸilimi

        # Frequency domain characteristics
        'fft_coeff_1': fft_coeffs[0] if len(fft_coeffs) > 0 else 0,
        'fft_coeff_2': fft_coeffs[1] if len(fft_coeffs) > 1 else 0,
        'fft_coeff_3': fft_coeffs[2] if len(fft_coeffs) > 2 else 0,
        'fft_coeff_4': fft_coeffs[3] if len(fft_coeffs) > 3 else 0,
        'fft_coeff_5': fft_coeffs[4] if len(fft_coeffs) > 4 else 0,

        # Basic statistical features for audio
        'mean_audio': np.mean(audio_signal),
        'std_audio': np.std(audio_signal),
        'max_audio': np.max(audio_signal),
        'min_audio': np.min(audio_signal),

        # Ses iÃ§in belirli Ã¶zellikler
        'signal_energy': np.sum(audio_signal**2),
        'rms_energy': np.sqrt(np.mean(audio_signal**2)),
        'zero_crossing_rate': np.mean(np.abs(np.diff(np.sign(audio_signal)))),
        'fft_peak_freq': np.argmax(fft_coeffs),
        'fft_bandwidth': np.std(fft_coeffs),
        'fft_entropy': entropy(fft_probs) if np.all(fft_probs > 0) else 0,
    }

    # MFCC Ã¶zellikleri (numcep=13 default)
    try:
        mfcc_features = mfcc(audio_signal.astype(np.float32), samplerate=16000, numcep=13)
        mfcc_mean = np.mean(mfcc_features, axis=0)
        for i, val in enumerate(mfcc_mean):
            features[f'mfcc_{i+1}'] = val
    except:
        for i in range(13):
            features[f'mfcc_{i+1}'] = 0

    return features

# --- Streamlit UygulamasÄ± ArayÃ¼zÃ¼ ---
st.title("Hasta Durumu Tahminleme UygulamasÄ±")
st.markdown("Yeni bir hasta iÃ§in `column1.txt`, `column3.txt` ve `metadata.txt` dosyalarÄ±nÄ± yÃ¼kleyerek hastalÄ±ÄŸÄ± tahmin edin.")

st.info("""
    **Ã–zellik Ã‡Ä±karÄ±mÄ± Bilgisi:**
    Bu uygulama, nefes ve ses sensÃ¶rÃ¼ verilerinden **seÃ§ili Ã¶zellikleri** kullanarak tahminleme yapar.
    Model 3 sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma yapar: **0 (Normal)**, **1 (Orta Risk)**, **2 (YÃ¼ksek Risk)**
""")

# --- Dosya YÃ¼kleyiciler ---
st.subheader("1. SensÃ¶r ve Metadata DosyalarÄ±nÄ± YÃ¼kleyin")

uploaded_col1_file = st.file_uploader("`column1.txt` (Nefes SensÃ¶rÃ¼ Verisi) YÃ¼kle", type="txt")
uploaded_col3_file = st.file_uploader("`column3.txt` (Ses SensÃ¶rÃ¼ Verisi) YÃ¼kle", type="txt")
uploaded_metadata_file = st.file_uploader("`metadata.txt` (Hasta Bilgileri) YÃ¼kle", type="txt")

if st.button("Tahmin Et"):
    if uploaded_col1_file and uploaded_col3_file and uploaded_metadata_file:
        try:
            # column1.txt oku
            breath_sensor_raw_str = uploaded_col1_file.read().decode("utf-8").strip()
            if breath_sensor_raw_str.startswith('[') and breath_sensor_raw_str.endswith(']'):
                breath_sensor_raw_str = breath_sensor_raw_str[1:-1]
            breath_sensor_data = np.array([float(x) for x in breath_sensor_raw_str.split('\n') if x.strip()])
            # column3.txt oku
            audio_sensor_data = np.array([float(x) for x in uploaded_col3_file.read().decode("utf-8").strip().split() if x.strip()])
            # metadata.txt oku
            metadata_lines = [line.strip() for line in uploaded_metadata_file.read().decode("latin-1").split('\n') if line.strip()]
            metadata_dict = {}
            for line in metadata_lines:
                if ":" in line:
                    key, value = line.split(":", 1)
                    metadata_dict[key.strip()] = value.strip()
            if not all(k in metadata_dict for k in ["Patient Name", "Date", "smoking", "age"]):
                st.error("Metadata dosyasÄ± eksik veya hatalÄ± formatta. LÃ¼tfen tÃ¼m alanlarÄ±n (Patient Name, Date, smoking, age) olduÄŸundan emin olun.")
                st.stop()
            patient_name_full = metadata_dict.get("Patient Name", "Bilinmeyen Ad")
            name_parts = patient_name_full.split(" ", 1)
            patient_name = name_parts[0] if name_parts else "Bilinmeyen"
            patient_surname = name_parts[1] if len(name_parts) > 1 else "Bilinmeyen"
            test_date_str = metadata_dict.get("Date", "")
            try:
                test_date = datetime.strptime(test_date_str, '%Y-%m-%d_%H-%M-%S')
            except ValueError:
                st.error(f"Metadata dosyasÄ±ndaki tarih formatÄ± hatalÄ±: {test_date_str}. Beklenen format: YYYY-MM-DD_HH-MM-SS")
                st.stop()
            is_smoking_status = metadata_dict.get("smoking", "no")
            age_str = metadata_dict.get("age", "0")
            try:
                patient_age = int(age_str)
            except ValueError:
                st.error(f"Metadata dosyasÄ±ndaki yaÅŸ deÄŸeri geÃ§ersiz: {age_str}. YaÅŸ bir sayÄ± olmalÄ±dÄ±r.")
                st.stop()
            st.subheader("2. Hasta Bilgileri ve Veri Analizi")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Hasta AdÄ±:** {patient_name} {patient_surname}")
                st.write(f"**YaÅŸ:** {patient_age}")
            with col2:
                st.write(f"**Test Tarihi:** {test_date.strftime('%Y-%m-%d %H:%M:%S')}")
                st.write(f"**Sigara Ä°Ã§iyor mu?:** {is_smoking_status.capitalize()}")
            st.write(f"**Nefes SensÃ¶rÃ¼ Veri NoktasÄ±:** {len(breath_sensor_data)}")
            st.write(f"**Ses SensÃ¶rÃ¼ Veri NoktasÄ±:** {len(audio_sensor_data)}")
            # Ã–zellik hesaplama
            st.subheader("3. Ã–zellik Hesaplama ve Analiz")
            with st.spinner("Ã–zellikler hesaplanÄ±yor..."):
                # Ham (unscaled) seÃ§ili Ã¶zellikler
                all_features = calculate_selected_features_only(breath_sensor_data, audio_sensor_data)
                raw_selected_features = [all_features[f] for f in selected_features]
                # Scaled Ã¶zellikler sadece bilgi iÃ§in
                features_2d = np.array(raw_selected_features).reshape(1, -1)
                scaled_features = scaler.transform(features_2d)
            st.write("**Hesaplanan SeÃ§ili Ã–zellikler (Ham):**")
            st.dataframe(pd.DataFrame([raw_selected_features], columns=selected_features), use_container_width=True)
            st.write("**Hesaplanan SeÃ§ili Ã–zellikler (Scale EdilmiÅŸ - Sadece Bilgi AmaÃ§lÄ±!):**")
            st.dataframe(pd.DataFrame([scaled_features[0]], columns=selected_features), use_container_width=True)
            # Tahmin Yap (HAM Ã¶zelliklerle!)
            st.subheader("4. Model Tahmini")
            with st.spinner("Model tahmini yapÄ±lÄ±yor..."):
                prediction = ensemble_model.predict([raw_selected_features])
                prediction_proba = ensemble_model.predict_proba([raw_selected_features])
                prediction_value = prediction[0]
                proba_values = prediction_proba[0]
            st.write("**Tahmin Sonucu:**")
            if prediction_value == 0:
                st.success(f"### âœ… **NORMAL DURUM** (SÄ±nÄ±f 0)")
                st.write("Hasta normal solunum fonksiyonlarÄ±na sahip gÃ¶rÃ¼nÃ¼yor.")
            elif prediction_value == 1:
                st.warning(f"### âš ï¸ **ORTA RÄ°SK** (SÄ±nÄ±f 1)")
                st.write("Hastada hafif solunum problemleri tespit edildi. Takip Ã¶nerilir.")
            elif prediction_value == 2:
                st.error(f"### ğŸš¨ **YÃœKSEK RÄ°SK** (SÄ±nÄ±f 2)")
                st.write("Hastada ciddi solunum problemleri tespit edildi. Acil deÄŸerlendirme gerekli.")
            else:
                st.info(f"### Bilinmeyen sÄ±nÄ±f: {prediction_value}")
            st.write("**Tahmin OlasÄ±lÄ±klarÄ±:**")
            proba_df = pd.DataFrame({
                'SÄ±nÄ±f': ['Normal (0)', 'Orta Risk (1)', 'YÃ¼ksek Risk (2)'],
                'OlasÄ±lÄ±k': proba_values,
                'YÃ¼zde': [f"{p*100:.2f}%" for p in proba_values]
            })
            st.dataframe(proba_df, use_container_width=True)
            st.write("**OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±:**")
            proba_chart = pd.DataFrame({
                'SÄ±nÄ±f': ['Normal', 'Orta Risk', 'YÃ¼ksek Risk'],
                'OlasÄ±lÄ±k': proba_values
            })
            st.bar_chart(proba_chart.set_index('SÄ±nÄ±f'))
        except Exception as e:
            st.error(f"Dosya iÅŸleme veya tahmin sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
            st.exception(e)
    else:
        st.warning("LÃ¼tfen tÃ¼m `column1.txt`, `column3.txt` ve `metadata.txt` dosyalarÄ±nÄ± yÃ¼kleyin.")

st.markdown("---")
st.sidebar.markdown("### Uygulama Bilgisi")
st.sidebar.info("""
Bu uygulama, nefes sensÃ¶rÃ¼, ses sensÃ¶rÃ¼ ve hasta metadata verilerini kullanarak 
bir makine Ã¶ÄŸrenimi modeli aracÄ±lÄ±ÄŸÄ±yla hasta durumunu tahmin eder.

**SÄ±nÄ±flar:**
- **0**: Normal durum
- **1**: Orta risk
- **2**: YÃ¼ksek risk

**SeÃ§ili Ã–zellikler:** 17 adet
""")

# SeÃ§ili Ã¶zellikleri sidebar'da gÃ¶ster
with st.sidebar.expander("SeÃ§ili Ã–zellikler"):
    st.write("Model tarafÄ±ndan kullanÄ±lan Ã¶zellikler:")
    for i, feature in enumerate(selected_features, 1):
        st.write(f"{i}. {feature}")